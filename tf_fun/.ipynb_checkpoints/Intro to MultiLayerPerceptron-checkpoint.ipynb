{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propriatary mnist management\n",
    "DATASETSLIB_HOME = './datasetslib'\n",
    "import sys\n",
    "if not DATASETSLIB_HOME in sys.path:\n",
    "    sys.path.append(DATASETSLIB_HOME)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasetslib\n",
    "\n",
    "from datasetslib import util as dsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetslib.datasets_root = os.path.join(os.path.expanduser('~'),'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/hackerman/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(os.path.join(datasetslib.datasets_root, 'mnist'),\n",
    "                                  one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "Y_train = mnist.train.labels\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 10 # image classes\n",
    "num_inputs = 784 # size of flattened image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w_55545'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"w_{0:04d}\".format(55545)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, num_inputs, num_outputs, num_layers, num_neurons):\n",
    "    w = []\n",
    "    b = []\n",
    "    for i in range(num_layers):\n",
    "        # weights\n",
    "        w.append(tf.Variable(tf.random_normal(\n",
    "            [num_inputs if i == 0 else num_neurons[i - 1],\n",
    "             num_neurons[i]]),\n",
    "            name=\"w_{0:04d}\".format(i)\n",
    "        ))\n",
    "        # biases\n",
    "        b.append(tf.Variable(tf.random_normal(\n",
    "            [num_neurons[i]]),\n",
    "            name=\"b_{0:04d}\".format(i)\n",
    "        ))\n",
    "    w.append(tf.Variable(tf.random_normal(\n",
    "        [num_neurons[num_layers - 1] if num_layers > 0 else num_inputs,\n",
    "         num_outputs]), name=\"w_out\"))\n",
    "    b.append(tf.Variable(tf.random_normal([num_outputs]), name=\"b_out\"))\n",
    "\n",
    "    # x is input layer\n",
    "    layer = x\n",
    "    # add hidden layers\n",
    "    for i in range(num_layers):\n",
    "        layer = tf.nn.relu(tf.matmul(layer, w[i]) + b[i])\n",
    "    # add output layer\n",
    "    layer = tf.matmul(layer, w[num_layers]) + b[num_layers]\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_func(batch_size=100):\n",
    "    X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "    return [X_batch, Y_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_classification( n_epochs, n_batches, batch_size, batch_func, model, optimizer, loss, accuracy_function,\n",
    "                             X_test, y_test):\n",
    "    with tf.Session() as tfs:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in range(n_batches):\n",
    "                X_train, y_train = batch_func(batch_size)\n",
    "                feed_dict = {x:X_train,y:y_train}\n",
    "                _, batch_loss = tfs.run([optimizer,loss],feed_dict=feed_dict)\n",
    "                epoch_loss += batch_loss\n",
    "            average_loss = batch_loss / n_batches\n",
    "            print('epoch: {0:04d} loss = {1:0.6f}'.format(epoch, average_loss))\n",
    "        # evaluating accuracy of model\n",
    "        feed_dict = {x:X_test,y:y_test}\n",
    "        accuracy_score = tfs.run(accuracy_function,feed_dict=feed_dict)\n",
    "        print('accuracy={0:.8f}'.format(accuracy_score))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000 loss = 0.009326\n",
      "epoch: 0001 loss = 0.007104\n",
      "epoch: 0002 loss = 0.005698\n",
      "epoch: 0003 loss = 0.003641\n",
      "epoch: 0004 loss = 0.003694\n",
      "epoch: 0005 loss = 0.002356\n",
      "epoch: 0006 loss = 0.002393\n",
      "epoch: 0007 loss = 0.002766\n",
      "epoch: 0008 loss = 0.002776\n",
      "epoch: 0009 loss = 0.001864\n",
      "epoch: 0010 loss = 0.003413\n",
      "epoch: 0011 loss = 0.002013\n",
      "epoch: 0012 loss = 0.002048\n",
      "epoch: 0013 loss = 0.003716\n",
      "epoch: 0014 loss = 0.002628\n",
      "epoch: 0015 loss = 0.002049\n",
      "epoch: 0016 loss = 0.001612\n",
      "epoch: 0017 loss = 0.001740\n",
      "epoch: 0018 loss = 0.001519\n",
      "epoch: 0019 loss = 0.000880\n",
      "epoch: 0020 loss = 0.002384\n",
      "epoch: 0021 loss = 0.001315\n",
      "epoch: 0022 loss = 0.001029\n",
      "epoch: 0023 loss = 0.002015\n",
      "epoch: 0024 loss = 0.001260\n",
      "epoch: 0025 loss = 0.000866\n",
      "epoch: 0026 loss = 0.001562\n",
      "epoch: 0027 loss = 0.000724\n",
      "epoch: 0028 loss = 0.000837\n",
      "epoch: 0029 loss = 0.001487\n",
      "epoch: 0030 loss = 0.002126\n",
      "epoch: 0031 loss = 0.001531\n",
      "epoch: 0032 loss = 0.002336\n",
      "epoch: 0033 loss = 0.000812\n",
      "epoch: 0034 loss = 0.001146\n",
      "epoch: 0035 loss = 0.001180\n",
      "epoch: 0036 loss = 0.001599\n",
      "epoch: 0037 loss = 0.001188\n",
      "epoch: 0038 loss = 0.000850\n",
      "epoch: 0039 loss = 0.001713\n",
      "epoch: 0040 loss = 0.001185\n",
      "epoch: 0041 loss = 0.002061\n",
      "epoch: 0042 loss = 0.001476\n",
      "epoch: 0043 loss = 0.001588\n",
      "epoch: 0044 loss = 0.001168\n",
      "epoch: 0045 loss = 0.001504\n",
      "epoch: 0046 loss = 0.001218\n",
      "epoch: 0047 loss = 0.000909\n",
      "epoch: 0048 loss = 0.001292\n",
      "epoch: 0049 loss = 0.001197\n",
      "accuracy=0.86170000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = tf.placeholder(dtype=tf.float32,shape=[None,num_inputs],name='x')\n",
    "y = tf.placeholder(dtype=tf.float32,shape=[None,num_outputs],name='y')\n",
    "\n",
    "num_layers = 0\n",
    "num_neurons = []\n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "model = mlp(x=x,\n",
    "            num_inputs=num_inputs,\n",
    "            num_outputs=num_outputs,\n",
    "            num_layers=num_layers,\n",
    "            num_neurons=num_neurons)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "prediction_check=tf.equal(tf.argmax(model,1),tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(prediction_check,tf.float32))\n",
    "\n",
    "tensorflow_classification(n_epochs=n_epochs,\n",
    "    n_batches=n_batches,\n",
    "    batch_size=batch_size,\n",
    "    batch_func=mnist_batch_func,\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    loss = loss,\n",
    "    accuracy_function = accuracy_function,\n",
    "    X_test = mnist.test.images,\n",
    "    y_test = mnist.test.labels\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets do it with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_neurons =[]\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "learning_rate = .01\n",
    "n_epochs = 50\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=num_neurons[0],activation='relu',input_shape=(num_inputs,)))\n",
    "model.add(Dense(units=num_neurons[1],activation='relu'))\n",
    "model.add(Dense(units=num_outputs,activation='softmax'))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:3086: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 18s 323us/step - loss: 1.1171 - acc: 0.7366\n",
      "\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 17s 310us/step - loss: 0.4401 - acc: 0.8830\n",
      "\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 418us/step - loss: 0.3551 - acc: 0.9003\n",
      "\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 27s 489us/step - loss: 0.3164 - acc: 0.9108\n",
      "\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 438us/step - loss: 0.2907 - acc: 0.9178\n",
      "\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 29s 527us/step - loss: 0.2705 - acc: 0.9231\n",
      "\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 26s 468us/step - loss: 0.2537 - acc: 0.9289\n",
      "\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 26s 478us/step - loss: 0.2389 - acc: 0.9326\n",
      "\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 423us/step - loss: 0.2264 - acc: 0.9361\n",
      "\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 414us/step - loss: 0.2150 - acc: 0.9394\n",
      "\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 388us/step - loss: 0.2048 - acc: 0.9418\n",
      "\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 398us/step - loss: 0.1953 - acc: 0.9448\n",
      "\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 406us/step - loss: 0.1871 - acc: 0.9471\n",
      "\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 419us/step - loss: 0.1790 - acc: 0.9490\n",
      "\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 410us/step - loss: 0.1723 - acc: 0.9510\n",
      "\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 406us/step - loss: 0.1655 - acc: 0.9527\n",
      "\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 394us/step - loss: 0.1595 - acc: 0.9543\n",
      "\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 395us/step - loss: 0.1535 - acc: 0.9562\n",
      "\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 388us/step - loss: 0.1482 - acc: 0.9579\n",
      "\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 430us/step - loss: 0.1430 - acc: 0.9591\n",
      "\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 436us/step - loss: 0.1382 - acc: 0.9607000 [===========================>..] - ETA: 0s - loss: 0.1379 \n",
      "\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 419us/step - loss: 0.1336 - acc: 0.9625\n",
      "\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 435us/step - loss: 0.1293 - acc: 0.9634\n",
      "\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 421us/step - loss: 0.1253 - acc: 0.9650\n",
      "\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 407us/step - loss: 0.1214 - acc: 0.9659\n",
      "\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 436us/step - loss: 0.1178 - acc: 0.9666\n",
      "\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 26s 470us/step - loss: 0.1144 - acc: 0.9679\n",
      "\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 414us/step - loss: 0.1111 - acc: 0.9687\n",
      "\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 377us/step - loss: 0.1081 - acc: 0.9698\n",
      "\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 20s 365us/step - loss: 0.1050 - acc: 0.9706\n",
      "\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 413us/step - loss: 0.1022 - acc: 0.9714\n",
      "\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 379us/step - loss: 0.0996 - acc: 0.9715\n",
      "\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 414us/step - loss: 0.0968 - acc: 0.9730\n",
      "\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 25s 446us/step - loss: 0.0943 - acc: 0.9736\n",
      "\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 387us/step - loss: 0.0917 - acc: 0.9745\n",
      "\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 375us/step - loss: 0.0895 - acc: 0.9752\n",
      "\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 20s 369us/step - loss: 0.0870 - acc: 0.9759\n",
      "\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 20s 367us/step - loss: 0.0854 - acc: 0.9764\n",
      "\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 409us/step - loss: 0.0831 - acc: 0.9771\n",
      "\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 27s 489us/step - loss: 0.0811 - acc: 0.9777\n",
      "\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 26s 477us/step - loss: 0.0793 - acc: 0.9783\n",
      "\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 28s 504us/step - loss: 0.0772 - acc: 0.9784\n",
      "\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 27s 499us/step - loss: 0.0756 - acc: 0.9791\n",
      "\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 29s 522us/step - loss: 0.0738 - acc: 0.9801\n",
      "\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 25s 457us/step - loss: 0.0720 - acc: 0.9802\n",
      "\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 378us/step - loss: 0.0705 - acc: 0.9806\n",
      "\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 399us/step - loss: 0.0688 - acc: 0.9812\n",
      "\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 400us/step - loss: 0.0674 - acc: 0.9819\n",
      "\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 435us/step - loss: 0.0656 - acc: 0.9827\n",
      "\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 379us/step - loss: 0.0644 - acc: 0.9826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f32a66fc518>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,batch_size=batch_size,epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================]10000/10000 [==============================] - 3s 253us/step\n",
      "\n",
      "\n",
      "\n",
      "Test loss :0.0895692008530721\n",
      "Test accuracy :0.974\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,Y_test)\n",
    "print('\\n\\nTest loss :{}'.format(score[0]))\n",
    "print('Test accuracy :{}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build deep neural network\n",
    "input_layer = tflearn.input_data(shape=[None, num_inputs])\n",
    "dense1 = tflearn.fully_connected(input_layer, num_neurons[0], activation='relu')\n",
    "dense2 = tflearn.fully_connected(dense1, num_neurons[1], activation='relu')\n",
    "softmax = tflearn.fully_connected(dense2, num_outputs, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tflearn.SGD(learning_rate=learning_rate)\n",
    "net = tflearn.regression(softmax,optimizer=optimizer,\n",
    "                        metric=tflearn.Accuracy(),\n",
    "                        loss = 'categorical_crossentropy')\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 27499  | total loss: \u001b[1m\u001b[32m0.09633\u001b[0m\u001b[0m | time: 17.335s\n",
      "| SGD | epoch: 050 | loss: 0.09633 - acc: 0.9737 -- iter: 54900/55000\n",
      "Training Step: 27500  | total loss: \u001b[1m\u001b[32m0.09236\u001b[0m\u001b[0m | time: 17.363s\n",
      "| SGD | epoch: 050 | loss: 0.09236 - acc: 0.9763 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          n_epoch=n_epochs,\n",
    "          batch_size=batch_size,\n",
    "          show_metric=True,\n",
    "          run_id='dense_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9669\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.624695  , 0.6378778 , 0.6407051 , 0.64242065, 0.64374477,\n",
       "       0.64425176, 0.6456537 , 0.645868  , 0.6515642 , 0.6520953 ,\n",
       "       0.6526113 , 0.653565  , 0.6542521 , 0.65997267, 0.6601886 ,\n",
       "       0.6602256 , 0.66157526, 0.6631329 , 0.664249  , 0.6645917 ,\n",
       "       0.66475666, 0.66641814, 0.6720195 , 0.6720384 , 0.6721242 ,\n",
       "       0.6725929 , 0.6770092 , 0.6822561 , 0.68308324, 0.6834013 ,\n",
       "       0.6839993 , 0.68601286, 0.68874943, 0.6920349 , 0.6930291 ,\n",
       "       0.6967098 , 0.6970987 , 0.69783443, 0.6982357 , 0.69872147,\n",
       "       0.69902635, 0.7000312 , 0.7000459 , 0.7029104 , 0.70558774,\n",
       "       0.7086226 , 0.7112784 , 0.71409786, 0.7141123 , 0.7150959 ,\n",
       "       0.7153938 , 0.7158679 , 0.7162591 , 0.7169752 , 0.71735305,\n",
       "       0.7209096 , 0.721864  , 0.7249994 , 0.72758937, 0.72948265,\n",
       "       0.73004293, 0.73034054, 0.7311133 , 0.73597455, 0.7400127 ,\n",
       "       0.74043846, 0.74051625, 0.7405334 , 0.7455783 , 0.7470599 ,\n",
       "       0.74720675, 0.74751145, 0.7485017 , 0.74987876, 0.7510674 ,\n",
       "       0.7510999 , 0.75128967, 0.75627655, 0.7568704 , 0.7576928 ,\n",
       "       0.758137  , 0.75859344, 0.7634491 , 0.76363033, 0.7648135 ,\n",
       "       0.76524025, 0.7663522 , 0.7677871 , 0.77013755, 0.78086877],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(datasetslib.datasets_root,'international-airline-passengers.csv')\n",
    "dataframe = pd.read_csv(filename,usecols=[1],header=0)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 48\n"
     ]
    }
   ],
   "source": [
    "train,test=dsu.train_test_split(dataset,train_size=0.67)\n",
    "print(len(train), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x=2\n",
    "n_y=1\n",
    "X_train, Y_train, X_test, Y_test = dsu.mvts_to_xy(train,test,n_x=n_x,n_y=n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = normalize(X_test)\n",
    "X_train = normalize(X_train)\n",
    "Y_test = normalize(Y_test)\n",
    "Y_train = normalize(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7229907 , 0.69085777],\n",
       "       [0.6456537 , 0.76363033],\n",
       "       [0.7150959 , 0.69902635],\n",
       "       [0.7000312 , 0.7141123 ],\n",
       "       [0.64374477, 0.76524025],\n",
       "       [0.6720384 , 0.74051625],\n",
       "       [0.70558774, 0.7086226 ],\n",
       "       [0.75627655, 0.6542521 ],\n",
       "       [0.75859344, 0.6515642 ],\n",
       "       [0.7510999 , 0.6601886 ],\n",
       "       [0.6721242 , 0.74043846],\n",
       "       [0.7029104 , 0.7112784 ],\n",
       "       [0.73034054, 0.68308324],\n",
       "       [0.65997267, 0.75128967],\n",
       "       [0.7209096 , 0.6930291 ],\n",
       "       [0.6920349 , 0.721864  ],\n",
       "       [0.6407051 , 0.7677871 ],\n",
       "       [0.6631329 , 0.7485017 ],\n",
       "       [0.6970987 , 0.7169752 ],\n",
       "       [0.78086877, 0.624695  ],\n",
       "       [0.74751145, 0.664249  ],\n",
       "       [0.7568704 , 0.653565  ],\n",
       "       [0.6770092 , 0.73597455],\n",
       "       [0.6834013 , 0.73004293],\n",
       "       [0.7249994 , 0.68874943],\n",
       "       [0.64425176, 0.7648135 ],\n",
       "       [0.7158679 , 0.6982357 ],\n",
       "       [0.68601286, 0.72758937],\n",
       "       [0.66475666, 0.7470599 ],\n",
       "       [0.6526113 , 0.7576928 ],\n",
       "       [0.7000459 , 0.71409786],\n",
       "       [0.77013755, 0.6378778 ],\n",
       "       [0.7510674 , 0.6602256 ],\n",
       "       [0.74720675, 0.6645917 ],\n",
       "       [0.66641814, 0.7455783 ],\n",
       "       [0.6967098 , 0.71735305],\n",
       "       [0.72948265, 0.6839993 ],\n",
       "       [0.6822561 , 0.7311133 ],\n",
       "       [0.6725929 , 0.7400127 ],\n",
       "       [0.69872147, 0.7153938 ],\n",
       "       [0.66157526, 0.74987876],\n",
       "       [0.6520953 , 0.758137  ],\n",
       "       [0.7162591 , 0.69783443],\n",
       "       [0.7663522 , 0.64242065],\n",
       "       [0.7405334 , 0.6720195 ],\n",
       "       [0.7634491 , 0.645868  ]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_neurons = [8,8]\n",
    "n_epochs = 50\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Dense(number of neurons, activation, shape of input to layers)\n",
    "model.add(Dense(num_neurons[0],activation='relu',input_shape=(n_x,)))\n",
    "# shape is not needed after first layer\n",
    "model.add(Dense(num_neurons[1],activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112., 118.],\n",
       "       [118., 132.],\n",
       "       [132., 129.],\n",
       "       [129., 121.],\n",
       "       [121., 135.],\n",
       "       [135., 148.],\n",
       "       [148., 148.],\n",
       "       [148., 136.],\n",
       "       [136., 119.],\n",
       "       [119., 104.],\n",
       "       [104., 118.],\n",
       "       [118., 115.],\n",
       "       [115., 126.],\n",
       "       [126., 141.],\n",
       "       [141., 135.],\n",
       "       [135., 125.],\n",
       "       [125., 149.],\n",
       "       [149., 170.],\n",
       "       [170., 170.],\n",
       "       [170., 158.],\n",
       "       [158., 133.],\n",
       "       [133., 114.],\n",
       "       [114., 140.],\n",
       "       [140., 145.],\n",
       "       [145., 150.],\n",
       "       [150., 178.],\n",
       "       [178., 163.],\n",
       "       [163., 172.],\n",
       "       [172., 178.],\n",
       "       [178., 199.],\n",
       "       [199., 199.],\n",
       "       [199., 184.],\n",
       "       [184., 162.],\n",
       "       [162., 146.],\n",
       "       [146., 166.],\n",
       "       [166., 171.],\n",
       "       [171., 180.],\n",
       "       [180., 193.],\n",
       "       [193., 181.],\n",
       "       [181., 183.],\n",
       "       [183., 218.],\n",
       "       [218., 230.],\n",
       "       [230., 242.],\n",
       "       [242., 209.],\n",
       "       [209., 191.],\n",
       "       [191., 172.],\n",
       "       [172., 194.],\n",
       "       [194., 196.],\n",
       "       [196., 196.],\n",
       "       [196., 236.],\n",
       "       [236., 235.],\n",
       "       [235., 229.],\n",
       "       [229., 243.],\n",
       "       [243., 264.],\n",
       "       [264., 272.],\n",
       "       [272., 237.],\n",
       "       [237., 211.],\n",
       "       [211., 180.],\n",
       "       [180., 201.],\n",
       "       [201., 204.],\n",
       "       [204., 188.],\n",
       "       [188., 235.],\n",
       "       [235., 227.],\n",
       "       [227., 234.],\n",
       "       [234., 264.],\n",
       "       [264., 302.],\n",
       "       [302., 293.],\n",
       "       [293., 259.],\n",
       "       [259., 229.],\n",
       "       [229., 203.],\n",
       "       [203., 229.],\n",
       "       [229., 242.],\n",
       "       [242., 233.],\n",
       "       [233., 267.],\n",
       "       [267., 269.],\n",
       "       [269., 270.],\n",
       "       [270., 315.],\n",
       "       [315., 364.],\n",
       "       [364., 347.],\n",
       "       [347., 312.],\n",
       "       [312., 274.],\n",
       "       [274., 237.],\n",
       "       [237., 278.],\n",
       "       [278., 284.],\n",
       "       [284., 277.],\n",
       "       [277., 317.],\n",
       "       [317., 313.],\n",
       "       [313., 318.],\n",
       "       [318., 374.],\n",
       "       [374., 413.],\n",
       "       [413., 405.],\n",
       "       [405., 355.],\n",
       "       [355., 306.],\n",
       "       [306., 271.]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile( loss , optimizer)\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112., 118.],\n",
       "       [118., 132.],\n",
       "       [132., 129.],\n",
       "       [129., 121.],\n",
       "       [121., 135.],\n",
       "       [135., 148.],\n",
       "       [148., 148.],\n",
       "       [148., 136.],\n",
       "       [136., 119.],\n",
       "       [119., 104.],\n",
       "       [104., 118.],\n",
       "       [118., 115.],\n",
       "       [115., 126.],\n",
       "       [126., 141.],\n",
       "       [141., 135.],\n",
       "       [135., 125.],\n",
       "       [125., 149.],\n",
       "       [149., 170.],\n",
       "       [170., 170.],\n",
       "       [170., 158.],\n",
       "       [158., 133.],\n",
       "       [133., 114.],\n",
       "       [114., 140.],\n",
       "       [140., 145.],\n",
       "       [145., 150.],\n",
       "       [150., 178.],\n",
       "       [178., 163.],\n",
       "       [163., 172.],\n",
       "       [172., 178.],\n",
       "       [178., 199.],\n",
       "       [199., 199.],\n",
       "       [199., 184.],\n",
       "       [184., 162.],\n",
       "       [162., 146.],\n",
       "       [146., 166.],\n",
       "       [166., 171.],\n",
       "       [171., 180.],\n",
       "       [180., 193.],\n",
       "       [193., 181.],\n",
       "       [181., 183.],\n",
       "       [183., 218.],\n",
       "       [218., 230.],\n",
       "       [230., 242.],\n",
       "       [242., 209.],\n",
       "       [209., 191.],\n",
       "       [191., 172.],\n",
       "       [172., 194.],\n",
       "       [194., 196.],\n",
       "       [196., 196.],\n",
       "       [196., 236.],\n",
       "       [236., 235.],\n",
       "       [235., 229.],\n",
       "       [229., 243.],\n",
       "       [243., 264.],\n",
       "       [264., 272.],\n",
       "       [272., 237.],\n",
       "       [237., 211.],\n",
       "       [211., 180.],\n",
       "       [180., 201.],\n",
       "       [201., 204.],\n",
       "       [204., 188.],\n",
       "       [188., 235.],\n",
       "       [235., 227.],\n",
       "       [227., 234.],\n",
       "       [234., 264.],\n",
       "       [264., 302.],\n",
       "       [302., 293.],\n",
       "       [293., 259.],\n",
       "       [259., 229.],\n",
       "       [229., 203.],\n",
       "       [203., 229.],\n",
       "       [229., 242.],\n",
       "       [242., 233.],\n",
       "       [233., 267.],\n",
       "       [267., 269.],\n",
       "       [269., 270.],\n",
       "       [270., 315.],\n",
       "       [315., 364.],\n",
       "       [364., 347.],\n",
       "       [347., 312.],\n",
       "       [312., 274.],\n",
       "       [274., 237.],\n",
       "       [237., 278.],\n",
       "       [278., 284.],\n",
       "       [284., 277.],\n",
       "       [277., 317.],\n",
       "       [317., 313.],\n",
       "       [313., 318.],\n",
       "       [318., 374.],\n",
       "       [374., 413.],\n",
       "       [413., 405.],\n",
       "       [405., 355.],\n",
       "       [355., 306.],\n",
       "       [306., 271.]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 10ms/step - loss: 23654.1414 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 2/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 6894.5684 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 3/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 1417.5613 - acc: 0.0106\n",
      "\n",
      "Epoch 4/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 665.4291 - acc: 0.0106\n",
      "\n",
      "Epoch 5/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 636.6537 - acc: 0.0426\n",
      "\n",
      "Epoch 6/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 5ms/step - loss: 633.9435 - acc: 0.0319\n",
      "\n",
      "Epoch 7/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 634.4627 - acc: 0.0426\n",
      "\n",
      "Epoch 8/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 637.6953 - acc: 0.0213\n",
      "\n",
      "Epoch 9/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 635.2568 - acc: 0.0213\n",
      "\n",
      "Epoch 10/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 641.1370 - acc: 0.0106\n",
      "\n",
      "Epoch 11/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 631.3152 - acc: 0.0106\n",
      "\n",
      "Epoch 12/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 635.3130 - acc: 0.0426\n",
      "\n",
      "Epoch 13/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 652.5920 - acc: 0.0213\n",
      "\n",
      "Epoch 14/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 9ms/step - loss: 644.4673 - acc: 0.0213\n",
      "\n",
      "Epoch 15/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 8ms/step - loss: 633.6061 - acc: 0.0106\n",
      "\n",
      "Epoch 16/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 635.5325 - acc: 0.0106\n",
      "\n",
      "Epoch 17/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 614.7171 - acc: 0.0106\n",
      "\n",
      "Epoch 18/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 594.8718 - acc: 0.0106\n",
      "\n",
      "Epoch 19/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 590.5242 - acc: 0.0106\n",
      "\n",
      "Epoch 20/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 569.8484 - acc: 0.0426\n",
      "\n",
      "Epoch 21/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 580.7122 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 22/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 578.1880 - acc: 0.0106\n",
      "\n",
      "Epoch 23/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 546.8590 - acc: 0.0213\n",
      "\n",
      "Epoch 24/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 5ms/step - loss: 547.8858 - acc: 0.0106\n",
      "\n",
      "Epoch 25/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 8ms/step - loss: 536.1302 - acc: 0.0106\n",
      "\n",
      "Epoch 26/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 542.7168 - acc: 0.0319\n",
      "\n",
      "Epoch 27/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 550.0175 - acc: 0.0532\n",
      "\n",
      "Epoch 28/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 8ms/step - loss: 536.2711 - acc: 0.0213\n",
      "\n",
      "Epoch 29/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 5ms/step - loss: 588.6796 - acc: 0.0319\n",
      "\n",
      "Epoch 30/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 566.6237 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 31/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 8ms/step - loss: 554.4099 - acc: 0.0426\n",
      "\n",
      "Epoch 32/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 9ms/step - loss: 542.8264 - acc: 0.0319\n",
      "\n",
      "Epoch 33/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 536.4460 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 34/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 8ms/step - loss: 530.4532 - acc: 0.0106\n",
      "\n",
      "Epoch 35/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 8ms/step - loss: 540.6597 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 36/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 532.2769 - acc: 0.0319\n",
      "\n",
      "Epoch 37/50\n",
      "94/94 [==============================]94/94 [==============================] - ETA: 0s - loss: 540.2541 - acc: 0.0326 - 1s 8ms/step - loss: 540.0499 - acc: 0.0319\n",
      "\n",
      "Epoch 38/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 521.2382 - acc: 0.0106\n",
      "\n",
      "Epoch 39/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 542.1701 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 40/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 8ms/step - loss: 532.0580 - acc: 0.0106\n",
      "\n",
      "Epoch 41/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 554.2087 - acc: 0.0532\n",
      "\n",
      "Epoch 42/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 524.2803 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 43/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 9ms/step - loss: 552.2698 - acc: 0.0213\n",
      "\n",
      "Epoch 44/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 534.1692 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 45/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 537.1363 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 46/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 519.9841 - acc: 0.0000e+00\n",
      "\n",
      "Epoch 47/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 535.0439 - acc: 0.0106\n",
      "\n",
      "Epoch 48/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 547.7662 - acc: 0.0319\n",
      "\n",
      "Epoch 49/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 522.7650 - acc: 0.0106\n",
      "\n",
      "Epoch 50/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 569.8512 - acc: 0.0106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit (input, output, batch_size, batch_number)\n",
    "history = model.fit(X_train,Y_train,batch_size=batch_size,epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================]46/46 [==============================] - 0s 2ms/step\n",
      "\n",
      "\n",
      "Test mse: [2193.838145380435, 0.043478260869565216]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test,verbose=1)\n",
    "print('\\nTest mse:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================]46/46 [==============================] - 0s 707us/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2193.838145380435, 0.043478260869565216]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46, 1), (46, 2))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make predictions\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# shift train predictions for plotting\n",
    "Y_train_pred_plot = np.empty_like(dataset)\n",
    "Y_train_pred_plot[:, :] = np.nan\n",
    "Y_train_pred_plot[n_x-1:len(Y_train_pred)+n_x-1, :] = Y_train_pred\n",
    "\n",
    "# shift test predictions for plotting\n",
    "Y_test_pred_plot = np.empty_like(dataset)\n",
    "Y_test_pred_plot[:, :] = np.nan\n",
    "Y_test_pred_plot[len(Y_train_pred)+(n_x*2)-1:len(dataset)-1, :] = Y_test_pred\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(dataset,label='Original Data')\n",
    "plt.plot(Y_train_pred_plot,label='Y_train_pred')\n",
    "plt.plot(Y_test_pred_plot,label='Y_test_pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[356.],\n",
       "       [348.],\n",
       "       [355.],\n",
       "       [422.],\n",
       "       [465.],\n",
       "       [467.],\n",
       "       [404.],\n",
       "       [347.],\n",
       "       [305.],\n",
       "       [336.],\n",
       "       [340.],\n",
       "       [318.],\n",
       "       [362.],\n",
       "       [348.],\n",
       "       [363.],\n",
       "       [435.],\n",
       "       [491.],\n",
       "       [505.],\n",
       "       [404.],\n",
       "       [359.],\n",
       "       [310.],\n",
       "       [337.],\n",
       "       [360.],\n",
       "       [342.],\n",
       "       [406.],\n",
       "       [396.],\n",
       "       [420.],\n",
       "       [472.],\n",
       "       [548.],\n",
       "       [559.],\n",
       "       [463.],\n",
       "       [407.],\n",
       "       [362.],\n",
       "       [405.],\n",
       "       [417.],\n",
       "       [391.],\n",
       "       [419.],\n",
       "       [461.],\n",
       "       [472.],\n",
       "       [535.],\n",
       "       [622.],\n",
       "       [606.],\n",
       "       [508.],\n",
       "       [461.],\n",
       "       [390.],\n",
       "       [432.]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46, 1), (94, 1), (144, 1))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_pred.shape, Y_train_pred.shape, dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([315., 301.], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(X_test[0],(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[470.1346]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.reshape(X_test[5],(-1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
