{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propriatary mnist management\n",
    "DATASETSLIB_HOME = './datasetslib'\n",
    "import sys\n",
    "if not DATASETSLIB_HOME in sys.path:\n",
    "    sys.path.append(DATASETSLIB_HOME)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasetslib\n",
    "\n",
    "from datasetslib import util as dsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetslib.datasets_root = os.path.join(os.path.expanduser('~'),'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/hackerman/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(os.path.join(datasetslib.datasets_root, 'mnist'),\n",
    "                                  one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "Y_train = mnist.train.labels\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outputs = 10 # image classes\n",
    "num_inputs = 784 # size of flattened image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w_55545'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"w_{0:04d}\".format(55545)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, num_inputs, num_outputs, num_layers, num_neurons):\n",
    "    w = []\n",
    "    b = []\n",
    "    for i in range(num_layers):\n",
    "        # weights\n",
    "        w.append(tf.Variable(tf.random_normal(\n",
    "            [num_inputs if i == 0 else num_neurons[i - 1],\n",
    "             num_neurons[i]]),\n",
    "            name=\"w_{0:04d}\".format(i)\n",
    "        ))\n",
    "        # biases\n",
    "        b.append(tf.Variable(tf.random_normal(\n",
    "            [num_neurons[i]]),\n",
    "            name=\"b_{0:04d}\".format(i)\n",
    "        ))\n",
    "    w.append(tf.Variable(tf.random_normal(\n",
    "        [num_neurons[num_layers - 1] if num_layers > 0 else num_inputs,\n",
    "         num_outputs]), name=\"w_out\"))\n",
    "    b.append(tf.Variable(tf.random_normal([num_outputs]), name=\"b_out\"))\n",
    "\n",
    "    # x is input layer\n",
    "    layer = x\n",
    "    # add hidden layers\n",
    "    for i in range(num_layers):\n",
    "        layer = tf.nn.relu(tf.matmul(layer, w[i]) + b[i])\n",
    "    # add output layer\n",
    "    layer = tf.matmul(layer, w[num_layers]) + b[num_layers]\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_func(batch_size=100):\n",
    "    X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "    return [X_batch, Y_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorflow_classification( n_epochs, n_batches, batch_size, batch_func, model, optimizer, loss, accuracy_function,\n",
    "                             X_test, y_test):\n",
    "    with tf.Session() as tfs:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in range(n_batches):\n",
    "                X_train, y_train = batch_func(batch_size)\n",
    "                feed_dict = {x:X_train,y:y_train}\n",
    "                _, batch_loss = tfs.run([optimizer,loss],feed_dict=feed_dict)\n",
    "                epoch_loss += batch_loss\n",
    "            average_loss = batch_loss / n_batches\n",
    "            print('epoch: {0:04d} loss = {1:0.6f}'.format(epoch, average_loss))\n",
    "        # evaluating accuracy of model\n",
    "        feed_dict = {x:X_test,y:y_test}\n",
    "        accuracy_score = tfs.run(accuracy_function,feed_dict=feed_dict)\n",
    "        print('accuracy={0:.8f}'.format(accuracy_score))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0000 loss = 0.009326\n",
      "epoch: 0001 loss = 0.007104\n",
      "epoch: 0002 loss = 0.005698\n",
      "epoch: 0003 loss = 0.003641\n",
      "epoch: 0004 loss = 0.003694\n",
      "epoch: 0005 loss = 0.002356\n",
      "epoch: 0006 loss = 0.002393\n",
      "epoch: 0007 loss = 0.002766\n",
      "epoch: 0008 loss = 0.002776\n",
      "epoch: 0009 loss = 0.001864\n",
      "epoch: 0010 loss = 0.003413\n",
      "epoch: 0011 loss = 0.002013\n",
      "epoch: 0012 loss = 0.002048\n",
      "epoch: 0013 loss = 0.003716\n",
      "epoch: 0014 loss = 0.002628\n",
      "epoch: 0015 loss = 0.002049\n",
      "epoch: 0016 loss = 0.001612\n",
      "epoch: 0017 loss = 0.001740\n",
      "epoch: 0018 loss = 0.001519\n",
      "epoch: 0019 loss = 0.000880\n",
      "epoch: 0020 loss = 0.002384\n",
      "epoch: 0021 loss = 0.001315\n",
      "epoch: 0022 loss = 0.001029\n",
      "epoch: 0023 loss = 0.002015\n",
      "epoch: 0024 loss = 0.001260\n",
      "epoch: 0025 loss = 0.000866\n",
      "epoch: 0026 loss = 0.001562\n",
      "epoch: 0027 loss = 0.000724\n",
      "epoch: 0028 loss = 0.000837\n",
      "epoch: 0029 loss = 0.001487\n",
      "epoch: 0030 loss = 0.002126\n",
      "epoch: 0031 loss = 0.001531\n",
      "epoch: 0032 loss = 0.002336\n",
      "epoch: 0033 loss = 0.000812\n",
      "epoch: 0034 loss = 0.001146\n",
      "epoch: 0035 loss = 0.001180\n",
      "epoch: 0036 loss = 0.001599\n",
      "epoch: 0037 loss = 0.001188\n",
      "epoch: 0038 loss = 0.000850\n",
      "epoch: 0039 loss = 0.001713\n",
      "epoch: 0040 loss = 0.001185\n",
      "epoch: 0041 loss = 0.002061\n",
      "epoch: 0042 loss = 0.001476\n",
      "epoch: 0043 loss = 0.001588\n",
      "epoch: 0044 loss = 0.001168\n",
      "epoch: 0045 loss = 0.001504\n",
      "epoch: 0046 loss = 0.001218\n",
      "epoch: 0047 loss = 0.000909\n",
      "epoch: 0048 loss = 0.001292\n",
      "epoch: 0049 loss = 0.001197\n",
      "accuracy=0.86170000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = tf.placeholder(dtype=tf.float32,shape=[None,num_inputs],name='x')\n",
    "y = tf.placeholder(dtype=tf.float32,shape=[None,num_outputs],name='y')\n",
    "\n",
    "num_layers = 0\n",
    "num_neurons = []\n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "n_batches = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "model = mlp(x=x,\n",
    "            num_inputs=num_inputs,\n",
    "            num_outputs=num_outputs,\n",
    "            num_layers=num_layers,\n",
    "            num_neurons=num_neurons)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "prediction_check=tf.equal(tf.argmax(model,1),tf.argmax(y,1))\n",
    "accuracy_function = tf.reduce_mean(tf.cast(prediction_check,tf.float32))\n",
    "\n",
    "tensorflow_classification(n_epochs=n_epochs,\n",
    "    n_batches=n_batches,\n",
    "    batch_size=batch_size,\n",
    "    batch_func=mnist_batch_func,\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    loss = loss,\n",
    "    accuracy_function = accuracy_function,\n",
    "    X_test = mnist.test.images,\n",
    "    y_test = mnist.test.labels\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets do it with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_neurons =[]\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "learning_rate = .01\n",
    "n_epochs = 50\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=num_neurons[0],activation='relu',input_shape=(num_inputs,)))\n",
    "model.add(Dense(units=num_neurons[1],activation='relu'))\n",
    "model.add(Dense(units=num_outputs,activation='softmax'))\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:3086: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 18s 323us/step - loss: 1.1171 - acc: 0.7366\n",
      "\n",
      "Epoch 2/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 17s 310us/step - loss: 0.4401 - acc: 0.8830\n",
      "\n",
      "Epoch 3/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 418us/step - loss: 0.3551 - acc: 0.9003\n",
      "\n",
      "Epoch 4/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 27s 489us/step - loss: 0.3164 - acc: 0.9108\n",
      "\n",
      "Epoch 5/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 438us/step - loss: 0.2907 - acc: 0.9178\n",
      "\n",
      "Epoch 6/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 29s 527us/step - loss: 0.2705 - acc: 0.9231\n",
      "\n",
      "Epoch 7/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 26s 468us/step - loss: 0.2537 - acc: 0.9289\n",
      "\n",
      "Epoch 8/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 26s 478us/step - loss: 0.2389 - acc: 0.9326\n",
      "\n",
      "Epoch 9/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 423us/step - loss: 0.2264 - acc: 0.9361\n",
      "\n",
      "Epoch 10/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 414us/step - loss: 0.2150 - acc: 0.9394\n",
      "\n",
      "Epoch 11/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 388us/step - loss: 0.2048 - acc: 0.9418\n",
      "\n",
      "Epoch 12/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 398us/step - loss: 0.1953 - acc: 0.9448\n",
      "\n",
      "Epoch 13/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 406us/step - loss: 0.1871 - acc: 0.9471\n",
      "\n",
      "Epoch 14/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 419us/step - loss: 0.1790 - acc: 0.9490\n",
      "\n",
      "Epoch 15/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 410us/step - loss: 0.1723 - acc: 0.9510\n",
      "\n",
      "Epoch 16/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 406us/step - loss: 0.1655 - acc: 0.9527\n",
      "\n",
      "Epoch 17/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 394us/step - loss: 0.1595 - acc: 0.9543\n",
      "\n",
      "Epoch 18/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 395us/step - loss: 0.1535 - acc: 0.9562\n",
      "\n",
      "Epoch 19/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 388us/step - loss: 0.1482 - acc: 0.9579\n",
      "\n",
      "Epoch 20/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 430us/step - loss: 0.1430 - acc: 0.9591\n",
      "\n",
      "Epoch 21/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 436us/step - loss: 0.1382 - acc: 0.9607000 [===========================>..] - ETA: 0s - loss: 0.1379 \n",
      "\n",
      "Epoch 22/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 419us/step - loss: 0.1336 - acc: 0.9625\n",
      "\n",
      "Epoch 23/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 435us/step - loss: 0.1293 - acc: 0.9634\n",
      "\n",
      "Epoch 24/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 421us/step - loss: 0.1253 - acc: 0.9650\n",
      "\n",
      "Epoch 25/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 407us/step - loss: 0.1214 - acc: 0.9659\n",
      "\n",
      "Epoch 26/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 436us/step - loss: 0.1178 - acc: 0.9666\n",
      "\n",
      "Epoch 27/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 26s 470us/step - loss: 0.1144 - acc: 0.9679\n",
      "\n",
      "Epoch 28/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 414us/step - loss: 0.1111 - acc: 0.9687\n",
      "\n",
      "Epoch 29/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 377us/step - loss: 0.1081 - acc: 0.9698\n",
      "\n",
      "Epoch 30/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 20s 365us/step - loss: 0.1050 - acc: 0.9706\n",
      "\n",
      "Epoch 31/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 413us/step - loss: 0.1022 - acc: 0.9714\n",
      "\n",
      "Epoch 32/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 379us/step - loss: 0.0996 - acc: 0.9715\n",
      "\n",
      "Epoch 33/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 23s 414us/step - loss: 0.0968 - acc: 0.9730\n",
      "\n",
      "Epoch 34/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 25s 446us/step - loss: 0.0943 - acc: 0.9736\n",
      "\n",
      "Epoch 35/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 387us/step - loss: 0.0917 - acc: 0.9745\n",
      "\n",
      "Epoch 36/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 375us/step - loss: 0.0895 - acc: 0.9752\n",
      "\n",
      "Epoch 37/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 20s 369us/step - loss: 0.0870 - acc: 0.9759\n",
      "\n",
      "Epoch 38/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 20s 367us/step - loss: 0.0854 - acc: 0.9764\n",
      "\n",
      "Epoch 39/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 409us/step - loss: 0.0831 - acc: 0.9771\n",
      "\n",
      "Epoch 40/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 27s 489us/step - loss: 0.0811 - acc: 0.9777\n",
      "\n",
      "Epoch 41/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 26s 477us/step - loss: 0.0793 - acc: 0.9783\n",
      "\n",
      "Epoch 42/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 28s 504us/step - loss: 0.0772 - acc: 0.9784\n",
      "\n",
      "Epoch 43/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 27s 499us/step - loss: 0.0756 - acc: 0.9791\n",
      "\n",
      "Epoch 44/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 29s 522us/step - loss: 0.0738 - acc: 0.9801\n",
      "\n",
      "Epoch 45/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 25s 457us/step - loss: 0.0720 - acc: 0.9802\n",
      "\n",
      "Epoch 46/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 378us/step - loss: 0.0705 - acc: 0.9806\n",
      "\n",
      "Epoch 47/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 399us/step - loss: 0.0688 - acc: 0.9812\n",
      "\n",
      "Epoch 48/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 22s 400us/step - loss: 0.0674 - acc: 0.9819\n",
      "\n",
      "Epoch 49/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 24s 435us/step - loss: 0.0656 - acc: 0.9827\n",
      "\n",
      "Epoch 50/50\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 21s 379us/step - loss: 0.0644 - acc: 0.9826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f32a66fc518>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,batch_size=batch_size,epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================]10000/10000 [==============================] - 3s 253us/step\n",
      "\n",
      "\n",
      "\n",
      "Test loss :0.0895692008530721\n",
      "Test accuracy :0.974\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,Y_test)\n",
    "print('\\n\\nTest loss :{}'.format(score[0]))\n",
    "print('Test accuracy :{}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_neurons = []\n",
    "for i in range(num_layers):\n",
    "    num_neurons.append(256)\n",
    "    \n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "batch_size = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build deep neural network\n",
    "input_layer = tflearn.input_data(shape=[None, num_inputs])\n",
    "dense1 = tflearn.fully_connected(input_layer, num_neurons[0], activation='relu')\n",
    "dense2 = tflearn.fully_connected(dense1, num_neurons[1], activation='relu')\n",
    "softmax = tflearn.fully_connected(dense2, num_outputs, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tflearn.SGD(learning_rate=learning_rate)\n",
    "net = tflearn.regression(softmax,optimizer=optimizer,\n",
    "                        metric=tflearn.Accuracy(),\n",
    "                        loss = 'categorical_crossentropy')\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 27499  | total loss: \u001b[1m\u001b[32m0.09633\u001b[0m\u001b[0m | time: 17.335s\n",
      "| SGD | epoch: 050 | loss: 0.09633 - acc: 0.9737 -- iter: 54900/55000\n",
      "Training Step: 27500  | total loss: \u001b[1m\u001b[32m0.09236\u001b[0m\u001b[0m | time: 17.363s\n",
      "| SGD | epoch: 050 | loss: 0.09236 - acc: 0.9763 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          n_epoch=n_epochs,\n",
    "          batch_size=batch_size,\n",
    "          show_metric=True,\n",
    "          run_id='dense_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9669\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(datasetslib.datasets_root,'international-airline-passengers.csv')\n",
    "dataframe = pd.read_csv(filename,usecols=[1],header=0)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "normalized_dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 48\n"
     ]
    }
   ],
   "source": [
    "train,test=dsu.train_test_split(normalized_dataset,train_size=0.67)\n",
    "print(len(train), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x=2\n",
    "n_y=1\n",
    "X_train, Y_train, X_test, Y_test = dsu.mvts_to_xy(train,test,n_x=n_x,n_y=n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05405405],\n",
       "       [0.04826255],\n",
       "       [0.03281853],\n",
       "       [0.05984557],\n",
       "       [0.08494207],\n",
       "       [0.08494207],\n",
       "       [0.06177607],\n",
       "       [0.02895753],\n",
       "       [0.        ],\n",
       "       [0.02702703],\n",
       "       [0.02123553],\n",
       "       [0.04247104],\n",
       "       [0.07142857],\n",
       "       [0.05984557],\n",
       "       [0.04054055],\n",
       "       [0.08687258],\n",
       "       [0.12741312],\n",
       "       [0.12741312],\n",
       "       [0.10424709],\n",
       "       [0.05598456],\n",
       "       [0.01930502],\n",
       "       [0.06949806],\n",
       "       [0.07915059],\n",
       "       [0.08880308],\n",
       "       [0.14285713],\n",
       "       [0.11389962],\n",
       "       [0.13127413],\n",
       "       [0.14285713],\n",
       "       [0.18339768],\n",
       "       [0.18339768],\n",
       "       [0.15444016],\n",
       "       [0.11196911],\n",
       "       [0.08108109],\n",
       "       [0.1196911 ],\n",
       "       [0.12934363],\n",
       "       [0.14671814],\n",
       "       [0.17181468],\n",
       "       [0.14864865],\n",
       "       [0.15250966],\n",
       "       [0.22007722],\n",
       "       [0.24324325],\n",
       "       [0.26640925],\n",
       "       [0.2027027 ],\n",
       "       [0.16795367],\n",
       "       [0.13127413],\n",
       "       [0.17374519],\n",
       "       [0.17760617],\n",
       "       [0.17760617],\n",
       "       [0.25482625],\n",
       "       [0.25289574],\n",
       "       [0.24131274],\n",
       "       [0.26833975],\n",
       "       [0.3088803 ],\n",
       "       [0.32432434],\n",
       "       [0.25675675],\n",
       "       [0.20656371],\n",
       "       [0.14671814],\n",
       "       [0.18725869],\n",
       "       [0.19305018],\n",
       "       [0.16216215],\n",
       "       [0.25289574],\n",
       "       [0.23745173],\n",
       "       [0.25096524],\n",
       "       [0.3088803 ],\n",
       "       [0.38223937],\n",
       "       [0.36486486],\n",
       "       [0.2992278 ],\n",
       "       [0.24131274],\n",
       "       [0.1911197 ],\n",
       "       [0.24131274],\n",
       "       [0.26640925],\n",
       "       [0.24903473],\n",
       "       [0.31467178],\n",
       "       [0.3185328 ],\n",
       "       [0.32046333],\n",
       "       [0.4073359 ],\n",
       "       [0.5019305 ],\n",
       "       [0.46911195],\n",
       "       [0.40154442],\n",
       "       [0.32818535],\n",
       "       [0.25675675],\n",
       "       [0.3359073 ],\n",
       "       [0.34749034],\n",
       "       [0.33397684],\n",
       "       [0.41119692],\n",
       "       [0.4034749 ],\n",
       "       [0.4131274 ],\n",
       "       [0.52123547],\n",
       "       [0.5965251 ],\n",
       "       [0.58108103],\n",
       "       [0.484556  ],\n",
       "       [0.3899614 ],\n",
       "       [0.3223938 ],\n",
       "       [0.3899614 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "num_neurons = [8,8]\n",
    "n_epochs = 50\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 105\n",
      "Trainable params: 105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Dense(number of neurons, activation, shape of input to layers)\n",
    "model.add(Dense(num_neurons[0],activation='relu',input_shape=(n_x,)))\n",
    "# shape is not needed after first layer\n",
    "model.add(Dense(num_neurons[1],activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01544401, 0.02702703],\n",
       "       [0.02702703, 0.05405405],\n",
       "       [0.05405405, 0.04826255],\n",
       "       [0.04826255, 0.03281853],\n",
       "       [0.03281853, 0.05984557],\n",
       "       [0.05984557, 0.08494207],\n",
       "       [0.08494207, 0.08494207],\n",
       "       [0.08494207, 0.06177607],\n",
       "       [0.06177607, 0.02895753],\n",
       "       [0.02895753, 0.        ],\n",
       "       [0.        , 0.02702703],\n",
       "       [0.02702703, 0.02123553],\n",
       "       [0.02123553, 0.04247104],\n",
       "       [0.04247104, 0.07142857],\n",
       "       [0.07142857, 0.05984557],\n",
       "       [0.05984557, 0.04054055],\n",
       "       [0.04054055, 0.08687258],\n",
       "       [0.08687258, 0.12741312],\n",
       "       [0.12741312, 0.12741312],\n",
       "       [0.12741312, 0.10424709],\n",
       "       [0.10424709, 0.05598456],\n",
       "       [0.05598456, 0.01930502],\n",
       "       [0.01930502, 0.06949806],\n",
       "       [0.06949806, 0.07915059],\n",
       "       [0.07915059, 0.08880308],\n",
       "       [0.08880308, 0.14285713],\n",
       "       [0.14285713, 0.11389962],\n",
       "       [0.11389962, 0.13127413],\n",
       "       [0.13127413, 0.14285713],\n",
       "       [0.14285713, 0.18339768],\n",
       "       [0.18339768, 0.18339768],\n",
       "       [0.18339768, 0.15444016],\n",
       "       [0.15444016, 0.11196911],\n",
       "       [0.11196911, 0.08108109],\n",
       "       [0.08108109, 0.1196911 ],\n",
       "       [0.1196911 , 0.12934363],\n",
       "       [0.12934363, 0.14671814],\n",
       "       [0.14671814, 0.17181468],\n",
       "       [0.17181468, 0.14864865],\n",
       "       [0.14864865, 0.15250966],\n",
       "       [0.15250966, 0.22007722],\n",
       "       [0.22007722, 0.24324325],\n",
       "       [0.24324325, 0.26640925],\n",
       "       [0.26640925, 0.2027027 ],\n",
       "       [0.2027027 , 0.16795367],\n",
       "       [0.16795367, 0.13127413],\n",
       "       [0.13127413, 0.17374519],\n",
       "       [0.17374519, 0.17760617],\n",
       "       [0.17760617, 0.17760617],\n",
       "       [0.17760617, 0.25482625],\n",
       "       [0.25482625, 0.25289574],\n",
       "       [0.25289574, 0.24131274],\n",
       "       [0.24131274, 0.26833975],\n",
       "       [0.26833975, 0.3088803 ],\n",
       "       [0.3088803 , 0.32432434],\n",
       "       [0.32432434, 0.25675675],\n",
       "       [0.25675675, 0.20656371],\n",
       "       [0.20656371, 0.14671814],\n",
       "       [0.14671814, 0.18725869],\n",
       "       [0.18725869, 0.19305018],\n",
       "       [0.19305018, 0.16216215],\n",
       "       [0.16216215, 0.25289574],\n",
       "       [0.25289574, 0.23745173],\n",
       "       [0.23745173, 0.25096524],\n",
       "       [0.25096524, 0.3088803 ],\n",
       "       [0.3088803 , 0.38223937],\n",
       "       [0.38223937, 0.36486486],\n",
       "       [0.36486486, 0.2992278 ],\n",
       "       [0.2992278 , 0.24131274],\n",
       "       [0.24131274, 0.1911197 ],\n",
       "       [0.1911197 , 0.24131274],\n",
       "       [0.24131274, 0.26640925],\n",
       "       [0.26640925, 0.24903473],\n",
       "       [0.24903473, 0.31467178],\n",
       "       [0.31467178, 0.3185328 ],\n",
       "       [0.3185328 , 0.32046333],\n",
       "       [0.32046333, 0.4073359 ],\n",
       "       [0.4073359 , 0.5019305 ],\n",
       "       [0.5019305 , 0.46911195],\n",
       "       [0.46911195, 0.40154442],\n",
       "       [0.40154442, 0.32818535],\n",
       "       [0.32818535, 0.25675675],\n",
       "       [0.25675675, 0.3359073 ],\n",
       "       [0.3359073 , 0.34749034],\n",
       "       [0.34749034, 0.33397684],\n",
       "       [0.33397684, 0.41119692],\n",
       "       [0.41119692, 0.4034749 ],\n",
       "       [0.4034749 , 0.4131274 ],\n",
       "       [0.4131274 , 0.52123547],\n",
       "       [0.52123547, 0.5965251 ],\n",
       "       [0.5965251 , 0.58108103],\n",
       "       [0.58108103, 0.484556  ],\n",
       "       [0.484556  , 0.3899614 ],\n",
       "       [0.3899614 , 0.3223938 ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile( loss , optimizer)\n",
    "model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01544401, 0.02702703],\n",
       "       [0.02702703, 0.05405405],\n",
       "       [0.05405405, 0.04826255],\n",
       "       [0.04826255, 0.03281853],\n",
       "       [0.03281853, 0.05984557],\n",
       "       [0.05984557, 0.08494207],\n",
       "       [0.08494207, 0.08494207],\n",
       "       [0.08494207, 0.06177607],\n",
       "       [0.06177607, 0.02895753],\n",
       "       [0.02895753, 0.        ],\n",
       "       [0.        , 0.02702703],\n",
       "       [0.02702703, 0.02123553],\n",
       "       [0.02123553, 0.04247104],\n",
       "       [0.04247104, 0.07142857],\n",
       "       [0.07142857, 0.05984557],\n",
       "       [0.05984557, 0.04054055],\n",
       "       [0.04054055, 0.08687258],\n",
       "       [0.08687258, 0.12741312],\n",
       "       [0.12741312, 0.12741312],\n",
       "       [0.12741312, 0.10424709],\n",
       "       [0.10424709, 0.05598456],\n",
       "       [0.05598456, 0.01930502],\n",
       "       [0.01930502, 0.06949806],\n",
       "       [0.06949806, 0.07915059],\n",
       "       [0.07915059, 0.08880308],\n",
       "       [0.08880308, 0.14285713],\n",
       "       [0.14285713, 0.11389962],\n",
       "       [0.11389962, 0.13127413],\n",
       "       [0.13127413, 0.14285713],\n",
       "       [0.14285713, 0.18339768],\n",
       "       [0.18339768, 0.18339768],\n",
       "       [0.18339768, 0.15444016],\n",
       "       [0.15444016, 0.11196911],\n",
       "       [0.11196911, 0.08108109],\n",
       "       [0.08108109, 0.1196911 ],\n",
       "       [0.1196911 , 0.12934363],\n",
       "       [0.12934363, 0.14671814],\n",
       "       [0.14671814, 0.17181468],\n",
       "       [0.17181468, 0.14864865],\n",
       "       [0.14864865, 0.15250966],\n",
       "       [0.15250966, 0.22007722],\n",
       "       [0.22007722, 0.24324325],\n",
       "       [0.24324325, 0.26640925],\n",
       "       [0.26640925, 0.2027027 ],\n",
       "       [0.2027027 , 0.16795367],\n",
       "       [0.16795367, 0.13127413],\n",
       "       [0.13127413, 0.17374519],\n",
       "       [0.17374519, 0.17760617],\n",
       "       [0.17760617, 0.17760617],\n",
       "       [0.17760617, 0.25482625],\n",
       "       [0.25482625, 0.25289574],\n",
       "       [0.25289574, 0.24131274],\n",
       "       [0.24131274, 0.26833975],\n",
       "       [0.26833975, 0.3088803 ],\n",
       "       [0.3088803 , 0.32432434],\n",
       "       [0.32432434, 0.25675675],\n",
       "       [0.25675675, 0.20656371],\n",
       "       [0.20656371, 0.14671814],\n",
       "       [0.14671814, 0.18725869],\n",
       "       [0.18725869, 0.19305018],\n",
       "       [0.19305018, 0.16216215],\n",
       "       [0.16216215, 0.25289574],\n",
       "       [0.25289574, 0.23745173],\n",
       "       [0.23745173, 0.25096524],\n",
       "       [0.25096524, 0.3088803 ],\n",
       "       [0.3088803 , 0.38223937],\n",
       "       [0.38223937, 0.36486486],\n",
       "       [0.36486486, 0.2992278 ],\n",
       "       [0.2992278 , 0.24131274],\n",
       "       [0.24131274, 0.1911197 ],\n",
       "       [0.1911197 , 0.24131274],\n",
       "       [0.24131274, 0.26640925],\n",
       "       [0.26640925, 0.24903473],\n",
       "       [0.24903473, 0.31467178],\n",
       "       [0.31467178, 0.3185328 ],\n",
       "       [0.3185328 , 0.32046333],\n",
       "       [0.32046333, 0.4073359 ],\n",
       "       [0.4073359 , 0.5019305 ],\n",
       "       [0.5019305 , 0.46911195],\n",
       "       [0.46911195, 0.40154442],\n",
       "       [0.40154442, 0.32818535],\n",
       "       [0.32818535, 0.25675675],\n",
       "       [0.25675675, 0.3359073 ],\n",
       "       [0.3359073 , 0.34749034],\n",
       "       [0.34749034, 0.33397684],\n",
       "       [0.33397684, 0.41119692],\n",
       "       [0.41119692, 0.4034749 ],\n",
       "       [0.4034749 , 0.4131274 ],\n",
       "       [0.4131274 , 0.52123547],\n",
       "       [0.52123547, 0.5965251 ],\n",
       "       [0.5965251 , 0.58108103],\n",
       "       [0.58108103, 0.484556  ],\n",
       "       [0.484556  , 0.3899614 ],\n",
       "       [0.3899614 , 0.3223938 ]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 11ms/step - loss: 0.0100 - acc: 0.0106\n",
      "\n",
      "Epoch 2/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 0.0106\n",
      "\n",
      "Epoch 3/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 0.0106\n",
      "\n",
      "Epoch 4/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 0.0106\n",
      "\n",
      "Epoch 5/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 0.0106\n",
      "\n",
      "Epoch 6/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 0.0106\n",
      "\n",
      "Epoch 7/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 0.0106\n",
      "\n",
      "Epoch 8/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 0.0021 - acc: 0.0106\n",
      "\n",
      "Epoch 9/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 0.0106\n",
      "\n",
      "Epoch 10/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 9ms/step - loss: 0.0021 - acc: 0.0106- ETA: 0s - loss: 0.0024 - acc: 0.00\n",
      "\n",
      "Epoch 11/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0021 - acc: 0.0106\n",
      "\n",
      "Epoch 12/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 9ms/step - loss: 0.0020 - acc: 0.0106\n",
      "\n",
      "Epoch 13/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0022 - acc: 0.0106\n",
      "\n",
      "Epoch 14/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 15/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0020 - acc: 0.0106- ETA: 0s - loss: 0.0020 - acc: 0.0109   \n",
      "\n",
      "Epoch 16/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0020 - acc: 0.0106\n",
      "\n",
      "Epoch 17/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 0.0106\n",
      "\n",
      "Epoch 18/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 19/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 10ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 20/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 21/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 22/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 0.0106\n",
      "\n",
      "Epoch 23/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 24/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0021 - acc: 0.0106\n",
      "\n",
      "Epoch 25/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 26/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 27/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 28/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 29/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 9ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 30/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 31/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 32/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 33/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 34/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 0.0020 - acc: 0.0106\n",
      "\n",
      "Epoch 35/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 36/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 37/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 38/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 8ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 39/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 40/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 0.0106\n",
      "\n",
      "Epoch 41/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 5ms/step - loss: 0.0017 - acc: 0.0106\n",
      "\n",
      "Epoch 42/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 43/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 44/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n",
      "Epoch 45/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 46/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 47/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 5ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 48/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 49/50\n",
      "94/94 [==============================]94/94 [==============================] - 1s 6ms/step - loss: 0.0018 - acc: 0.0106\n",
      "\n",
      "Epoch 50/50\n",
      "94/94 [==============================]94/94 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 0.0106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit (input, output, batch_size, batch_number)\n",
    "history = model.fit(X_train,Y_train,batch_size=batch_size,epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================]46/46 [==============================] - 0s 2ms/step\n",
      "\n",
      "\n",
      "Test mse: [0.01153335412559302, 0.02173913140659747]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test,verbose=1)\n",
    "print('\\nTest mse:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================]46/46 [==============================] - 0s 357us/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00011391338794846493, 1.0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01544401],\n",
       "       [0.02702703],\n",
       "       [0.05405405],\n",
       "       [0.04826255],\n",
       "       [0.03281853],\n",
       "       [0.05984557],\n",
       "       [0.08494207],\n",
       "       [0.08494207],\n",
       "       [0.06177607],\n",
       "       [0.02895753],\n",
       "       [0.        ],\n",
       "       [0.02702703],\n",
       "       [0.02123553],\n",
       "       [0.04247104],\n",
       "       [0.07142857],\n",
       "       [0.05984557],\n",
       "       [0.04054055],\n",
       "       [0.08687258],\n",
       "       [0.12741312],\n",
       "       [0.12741312],\n",
       "       [0.10424709],\n",
       "       [0.05598456],\n",
       "       [0.01930502],\n",
       "       [0.06949806],\n",
       "       [0.07915059],\n",
       "       [0.08880308],\n",
       "       [0.14285713],\n",
       "       [0.11389962],\n",
       "       [0.13127413],\n",
       "       [0.14285713],\n",
       "       [0.18339768],\n",
       "       [0.18339768],\n",
       "       [0.15444016],\n",
       "       [0.11196911],\n",
       "       [0.08108109],\n",
       "       [0.1196911 ],\n",
       "       [0.12934363],\n",
       "       [0.14671814],\n",
       "       [0.17181468],\n",
       "       [0.14864865],\n",
       "       [0.15250966],\n",
       "       [0.22007722],\n",
       "       [0.24324325],\n",
       "       [0.26640925],\n",
       "       [0.2027027 ],\n",
       "       [0.16795367],\n",
       "       [0.13127413],\n",
       "       [0.17374519],\n",
       "       [0.17760617],\n",
       "       [0.17760617],\n",
       "       [0.25482625],\n",
       "       [0.25289574],\n",
       "       [0.24131274],\n",
       "       [0.26833975],\n",
       "       [0.3088803 ],\n",
       "       [0.32432434],\n",
       "       [0.25675675],\n",
       "       [0.20656371],\n",
       "       [0.14671814],\n",
       "       [0.18725869],\n",
       "       [0.19305018],\n",
       "       [0.16216215],\n",
       "       [0.25289574],\n",
       "       [0.23745173],\n",
       "       [0.25096524],\n",
       "       [0.3088803 ],\n",
       "       [0.38223937],\n",
       "       [0.36486486],\n",
       "       [0.2992278 ],\n",
       "       [0.24131274],\n",
       "       [0.1911197 ],\n",
       "       [0.24131274],\n",
       "       [0.26640925],\n",
       "       [0.24903473],\n",
       "       [0.31467178],\n",
       "       [0.3185328 ],\n",
       "       [0.32046333],\n",
       "       [0.4073359 ],\n",
       "       [0.5019305 ],\n",
       "       [0.46911195],\n",
       "       [0.40154442],\n",
       "       [0.32818535],\n",
       "       [0.25675675],\n",
       "       [0.3359073 ],\n",
       "       [0.34749034],\n",
       "       [0.33397684],\n",
       "       [0.41119692],\n",
       "       [0.4034749 ],\n",
       "       [0.4131274 ],\n",
       "       [0.52123547],\n",
       "       [0.5965251 ],\n",
       "       [0.58108103],\n",
       "       [0.484556  ],\n",
       "       [0.3899614 ],\n",
       "       [0.3223938 ],\n",
       "       [0.3899614 ],\n",
       "       [0.4073359 ],\n",
       "       [0.3803089 ],\n",
       "       [0.48648646],\n",
       "       [0.47104248],\n",
       "       [0.484556  ],\n",
       "       [0.6138996 ],\n",
       "       [0.6969112 ],\n",
       "       [0.70077217],\n",
       "       [0.57915056],\n",
       "       [0.46911195],\n",
       "       [0.38803086],\n",
       "       [0.44787642],\n",
       "       [0.45559844],\n",
       "       [0.4131274 ],\n",
       "       [0.4980695 ],\n",
       "       [0.47104248],\n",
       "       [0.49999997],\n",
       "       [0.6389961 ],\n",
       "       [0.7471043 ],\n",
       "       [0.7741313 ],\n",
       "       [0.57915056],\n",
       "       [0.492278  ],\n",
       "       [0.3976834 ],\n",
       "       [0.44980696],\n",
       "       [0.49420848],\n",
       "       [0.45945945],\n",
       "       [0.5830116 ],\n",
       "       [0.5637065 ],\n",
       "       [0.61003864],\n",
       "       [0.71042466],\n",
       "       [0.8571429 ],\n",
       "       [0.8783784 ],\n",
       "       [0.69305015],\n",
       "       [0.5849421 ],\n",
       "       [0.4980695 ],\n",
       "       [0.58108103],\n",
       "       [0.6042471 ],\n",
       "       [0.554054  ],\n",
       "       [0.60810804],\n",
       "       [0.6891892 ],\n",
       "       [0.71042466],\n",
       "       [0.8320464 ],\n",
       "       [1.        ],\n",
       "       [0.96911204],\n",
       "       [0.7799227 ],\n",
       "       [0.6891892 ],\n",
       "       [0.55212355],\n",
       "       [0.6332046 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05405405],\n",
       "       [0.04826255],\n",
       "       [0.03281853],\n",
       "       [0.05984557],\n",
       "       [0.08494207],\n",
       "       [0.08494207],\n",
       "       [0.06177607],\n",
       "       [0.02895753],\n",
       "       [0.        ],\n",
       "       [0.02702703],\n",
       "       [0.02123553],\n",
       "       [0.04247104],\n",
       "       [0.07142857],\n",
       "       [0.05984557],\n",
       "       [0.04054055],\n",
       "       [0.08687258],\n",
       "       [0.12741312],\n",
       "       [0.12741312],\n",
       "       [0.10424709],\n",
       "       [0.05598456],\n",
       "       [0.01930502],\n",
       "       [0.06949806],\n",
       "       [0.07915059],\n",
       "       [0.08880308],\n",
       "       [0.14285713],\n",
       "       [0.11389962],\n",
       "       [0.13127413],\n",
       "       [0.14285713],\n",
       "       [0.18339768],\n",
       "       [0.18339768],\n",
       "       [0.15444016],\n",
       "       [0.11196911],\n",
       "       [0.08108109],\n",
       "       [0.1196911 ],\n",
       "       [0.12934363],\n",
       "       [0.14671814],\n",
       "       [0.17181468],\n",
       "       [0.14864865],\n",
       "       [0.15250966],\n",
       "       [0.22007722],\n",
       "       [0.24324325],\n",
       "       [0.26640925],\n",
       "       [0.2027027 ],\n",
       "       [0.16795367],\n",
       "       [0.13127413],\n",
       "       [0.17374519],\n",
       "       [0.17760617],\n",
       "       [0.17760617],\n",
       "       [0.25482625],\n",
       "       [0.25289574],\n",
       "       [0.24131274],\n",
       "       [0.26833975],\n",
       "       [0.3088803 ],\n",
       "       [0.32432434],\n",
       "       [0.25675675],\n",
       "       [0.20656371],\n",
       "       [0.14671814],\n",
       "       [0.18725869],\n",
       "       [0.19305018],\n",
       "       [0.16216215],\n",
       "       [0.25289574],\n",
       "       [0.23745173],\n",
       "       [0.25096524],\n",
       "       [0.3088803 ],\n",
       "       [0.38223937],\n",
       "       [0.36486486],\n",
       "       [0.2992278 ],\n",
       "       [0.24131274],\n",
       "       [0.1911197 ],\n",
       "       [0.24131274],\n",
       "       [0.26640925],\n",
       "       [0.24903473],\n",
       "       [0.31467178],\n",
       "       [0.3185328 ],\n",
       "       [0.32046333],\n",
       "       [0.4073359 ],\n",
       "       [0.5019305 ],\n",
       "       [0.46911195],\n",
       "       [0.40154442],\n",
       "       [0.32818535],\n",
       "       [0.25675675],\n",
       "       [0.3359073 ],\n",
       "       [0.34749034],\n",
       "       [0.33397684],\n",
       "       [0.41119692],\n",
       "       [0.4034749 ],\n",
       "       [0.4131274 ],\n",
       "       [0.52123547],\n",
       "       [0.5965251 ],\n",
       "       [0.58108103],\n",
       "       [0.484556  ],\n",
       "       [0.3899614 ],\n",
       "       [0.3223938 ],\n",
       "       [0.3899614 ]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46, 1), (46, 2))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 143)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train_pred)+(n_x*2)-1,len(normalized_dataset)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make predictions\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# shift train predictions for plotting\n",
    "Y_train_pred_plot = np.empty_like(normalized_dataset)\n",
    "Y_train_pred_plot[:, :] = np.nan\n",
    "Y_train_pred_plot[n_x-1:len(Y_train_pred)+n_x-1, :] = Y_train_pred\n",
    "\n",
    "# shift test predictions for plotting\n",
    "Y_test_pred_plot = np.empty_like(normalized_dataset)\n",
    "Y_test_pred_plot[:, :] = np.nan\n",
    "Y_test_pred_plot[len(Y_train_pred)+(n_x*2)-1:len(normalized_dataset)-1, :] = Y_test_pred\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(normalized_dataset,label='Original Data')\n",
    "plt.plot(Y_train_pred_plot,label='Y_train_pred')\n",
    "plt.plot(Y_test_pred_plot,label='Y_test_pred')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[356.],\n",
       "       [348.],\n",
       "       [355.],\n",
       "       [422.],\n",
       "       [465.],\n",
       "       [467.],\n",
       "       [404.],\n",
       "       [347.],\n",
       "       [305.],\n",
       "       [336.],\n",
       "       [340.],\n",
       "       [318.],\n",
       "       [362.],\n",
       "       [348.],\n",
       "       [363.],\n",
       "       [435.],\n",
       "       [491.],\n",
       "       [505.],\n",
       "       [404.],\n",
       "       [359.],\n",
       "       [310.],\n",
       "       [337.],\n",
       "       [360.],\n",
       "       [342.],\n",
       "       [406.],\n",
       "       [396.],\n",
       "       [420.],\n",
       "       [472.],\n",
       "       [548.],\n",
       "       [559.],\n",
       "       [463.],\n",
       "       [407.],\n",
       "       [362.],\n",
       "       [405.],\n",
       "       [417.],\n",
       "       [391.],\n",
       "       [419.],\n",
       "       [461.],\n",
       "       [472.],\n",
       "       [535.],\n",
       "       [622.],\n",
       "       [606.],\n",
       "       [508.],\n",
       "       [461.],\n",
       "       [390.],\n",
       "       [432.]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46, 1), (94, 1), (144, 1))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_pred.shape, Y_train_pred.shape, dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([315., 301.], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(X_test[0],(2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[470.1346]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.reshape(X_test[5],(-1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
