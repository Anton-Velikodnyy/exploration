{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "## Steps to Success\n",
    "1. Create input and output placeholders of shape (None,# timesteps,# features) or (Batch Size, # timesteps,# features).\n",
    "2. From the input placeholder, create a list of length # timesteps, containing Tensor of Shape (None, # features) or (Batch Size, # features).\n",
    "3. Create a cell of the desired RNN type from tf.rnn.rnn_cell module.\n",
    "4. Use the cell and previous input to create a static or dynamic RNN.\n",
    "5. Create the output weights and bias variables, and define the loss and optimizer functions.\n",
    "6. For the required number of epochs, train the model using the loss and optimizer functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If an image is 28x28, then it can be split inot 28 timesteps for 28 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "from tensorflow.python.keras.layers import SimpleRNN\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETSLIB_HOME = '../datasetslib'\n",
    "import sys\n",
    "if not DATASETSLIB_HOME in sys.path:\n",
    "    sys.path.append(DATASETSLIB_HOME)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasetslib\n",
    "\n",
    "datasetslib.datasets_root = os.path.join(os.path.expanduser('~'),'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/hackerman/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/hackerman/datasets/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Prepping MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(os.path.join(datasetslib.datasets_root,'mnist'),one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist.train.images\n",
    "X_test = mnist.test.images\n",
    "Y_train = mnist.train.labels\n",
    "Y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "X_train = X_train.reshape(-1,28,28)\n",
    "X_test = X_test.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_3 (SimpleRNN)     (None, 16)                720       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 890\n",
      "Trainable params: 890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the simple RNN\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=16,activation='relu',input_shape=(28,28)))\n",
    "model.add(Dense(n_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(lr=.01),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 35s 629us/step - loss: 1.2777 - acc: 0.5395\n",
      "\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 34s 620us/step - loss: 0.8778 - acc: 0.7077\n",
      "\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 39s 709us/step - loss: 0.7778 - acc: 0.7325\n",
      "\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 34s 614us/step - loss: 0.7299 - acc: 0.7557\n",
      "\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 34s 614us/step - loss: 0.6677 - acc: 0.7893\n",
      "\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 35s 630us/step - loss: 0.6484 - acc: 0.8037\n",
      "\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 34s 626us/step - loss: 0.6623 - acc: 0.8128\n",
      "\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 35s 634us/step - loss: 0.7084 - acc: 0.8135\n",
      "\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 36s 652us/step - loss: 0.6027 - acc: 0.8282\n",
      "\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 35s 640us/step - loss: 2.0969 - acc: 0.7391\n",
      "\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 34s 624us/step - loss: 1.3715 - acc: 0.7592\n",
      "\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 40s 735us/step - loss: 0.9598 - acc: 0.7853\n",
      "\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 29s 519us/step - loss: 1.0056 - acc: 0.7922\n",
      "\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 30s 555us/step - loss: 1.0669 - acc: 0.7837\n",
      "\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 28s 505us/step - loss: 2.1113 - acc: 0.7179\n",
      "\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 29s 529us/step - loss: 1.3230 - acc: 0.7310\n",
      "\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 30s 552us/step - loss: 1.3330 - acc: 0.7445\n",
      "\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 28s 508us/step - loss: 7.7608 - acc: 0.4329\n",
      "\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 29s 529us/step - loss: 14.5233 - acc: 0.0989\n",
      "\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================]55000/55000 [==============================] - 43s 790us/step - loss: 14.5227 - acc: 0.0990\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f9bfc605908>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,batch_size=100,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================]10000/10000 [==============================] - 6s 597us/step\n",
      "\n",
      "Test loss: 14.538521841430665\n",
      "Test accuracy: 0.098\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,Y_test)\n",
    "print(\"Test loss: {}\".format(score[0]))\n",
    "print(\"Test accuracy: {}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
