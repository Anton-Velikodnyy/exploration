{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.python.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "## 5 Steps to Success\n",
    "1. Create the model\n",
    "2. Create and add layers to the model\n",
    "3. Compile the model\n",
    "4. Train the model\n",
    "5. Use the model to predict\n",
    "\n",
    "### Sequantial vs Functional models\n",
    "- Sequantial: easier to build, light-weight\n",
    "- Functional: allows for more complex models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequantial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Activation, Dense\n",
    "model = Sequential()\n",
    "\n",
    "# 4 layers passed into the constructor in the form of a list\n",
    "# 1 + 2\n",
    "model = Sequential([ \n",
    "    Dense(10, input_shape=(256,)),\n",
    "    Activation('tanh'),\n",
    "    Dense(10),\n",
    "    Activation('softmax')])\n",
    "# or\n",
    "# 1\n",
    "model = Sequential()\n",
    "# 2\n",
    "model.add(Dense(10, input_shape=(256,)))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.models import Model\n",
    "# 2\n",
    "inputs = Input(shape=(64,))\n",
    "hidden = Dense(10)(inputs)\n",
    "hidden = Activation('tanh')(hidden)\n",
    "hidden = Dense(10)(hidden)\n",
    "output = Activation('tanh')(hidden)\n",
    "# 1\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "#model.compile(self, optimizer, loss, metrics=None, sample_weight_mode=None)\n",
    "# string could be replaced with function that is defined elsewhere\n",
    "#model.compile(optimizer=Adam(), loss=mean_squared_error(), metrics=['accuracy'], sample_weight_mode=None)\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['accuracy'], sample_weight_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None,\n",
    "# validation_split=0.0, validation_data=None, shuffle=True,\n",
    "# class_weight=None, sample_weight=None, initial_epoch=0)\n",
    "# easy life\n",
    "# model.fit(x_data, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "# predict(self, x, batch_size=32, verbose=0)\n",
    "# evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================]11493376/11490434 [==============================] - 4s 0us/step\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:3086: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/hackerman/anaconda2/envs/py36/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 21s 343us/step - loss: 2.3037 - acc: 0.1244\n",
      "\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 21s 356us/step - loss: 2.2374 - acc: 0.1913\n",
      "\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 29s 476us/step - loss: 2.1537 - acc: 0.2824\n",
      "\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 23s 387us/step - loss: 2.0238 - acc: 0.3926\n",
      "\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 26s 428us/step - loss: 1.8262 - acc: 0.4867\n",
      "\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 19s 324us/step - loss: 1.5924 - acc: 0.5599\n",
      "\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 18s 297us/step - loss: 1.3755 - acc: 0.6206\n",
      "\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 18s 300us/step - loss: 1.1974 - acc: 0.6679\n",
      "\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 24s 402us/step - loss: 1.0586 - acc: 0.7059\n",
      "\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================]60000/60000 [==============================] - 29s 476us/step - loss: 0.9536 - acc: 0.7324\n",
      "\n",
      "10000/10000 [==============================]10000/10000 [==============================] - 3s 284us/step\n",
      "\n",
      "\n",
      " loss: 0.8305067066192627\n",
      "\n",
      " accuracy: 0.8068\n"
     ]
    }
   ],
   "source": [
    "# import the keras modules\n",
    "import tensorflow.python.keras\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras import utils\n",
    "import numpy as np\n",
    "\n",
    "# define some hyper parameters\n",
    "batch_size = 100\n",
    "n_inputs = 784\n",
    "n_classes = 10\n",
    "n_epochs = 10\n",
    "\n",
    "# get the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the two dimensional 28 x 28 pixels\n",
    "#   sized images into a single vector of 784 pixels\n",
    "x_train = x_train.reshape(60000, n_inputs)\n",
    "x_test = x_test.reshape(10000, n_inputs)\n",
    "\n",
    "# convert the input values to float32\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "# normalize the values of image vectors to fit under 1\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert output data into one hot encoded format\n",
    "y_train = utils.to_categorical(y_train, n_classes)\n",
    "y_test = utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "# build a sequential model\n",
    "model = Sequential()\n",
    "# the first layer has to specify the dimensions of the input vector\n",
    "model.add(Dense(units=128, activation='sigmoid', input_shape=(n_inputs,)))\n",
    "# add dropout layer for preventing overfitting\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=128, activation='sigmoid'))\n",
    "model.add(Dropout(0.1))\n",
    "# output layer can only have the neurons equal to the number of outputs\n",
    "model.add(Dense(units=n_classes, activation='softmax'))\n",
    "\n",
    "# print the summary of our model\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs)\n",
    "\n",
    "# evaluate the model and print the accuracy score\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('\\n loss:', scores[0])\n",
    "print('\\n accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
